
import streamlit as st
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
import plotly.graph_objects as go
import cv2
import json
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras.metrics import Precision, Recall

import google.generativeai as genai
import PIL.Image
import os
from google.colab import userdata
from dotenv import load_dotenv
load_dotenv()


genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))

output_dir = 'saliency_maps'
os.makedirs(output_dir, exist_ok=True)

def load_model_and_history_from_file(filepath):
  keras_file = '/content/' + filepath + ".keras"
  json_file = '/content/history_' + filepath +'.json'

  model = load_model(keras_file, compile=True)

  with open(json_file, 'r') as f:
      history = json.load(f)
  return model, history

def generate_explanation(img_path, model_prediction, confidence):
  prompt = f"""
    You are a n expert neurologist. You are tasked with explaning a saliency map of a brain tumor MRI scan.
    The saliency map was generated by a deep learning model that was trained to classify brain tumors
    as either glioma, meningioma, pituitary, or no tumor.

    The saliency map highlights the regions of the image that the machine learning model is focusing on to make the prediction.

    The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%.

    In your response:
    - Explain what regions of the brain the model is focusing on, based on teh saliency map. Refer to the regions highlighted
    in light cyan, those are the regions where the model is focusing on.
    - Explain possible reasons why the model made the prediction it did.
    - Don't mention anything like 'The saliency map highlights the regions the model is focusing on, which are in light cyan'
    in your explanation.
    - Keep your explanation to 4 sentences max.

    Let's think step by step about this. Verify step by step.
  """

  img = PIL.Image.open(img_path)

  model = genai.GenerativeModel(model_name='gemini-1.5-flash')
  response = model.generate_content([prompt, img])
  return response.text

def generate_saliency_map(model, img_array, class_index, img_size):
  with tf.GradientTape() as tape:
    img_tensor = tf.convert_to_tensor(img_array)
    tape.watch(img_tensor)
    predictions = model(img_tensor)
    target_class = predictions[:, class_index]

  gradients = tape.gradient(target_class, img_tensor)
  gradients = tf.math.abs(gradients)
  gradients = tf.reduce_max(gradients, axis=-1)
  gradients = gradients.numpy().squeeze()

  # Resize gradients to match original image size
  gradients = cv2.resize(gradients, img_size)

  # Create a circular mask for the brain area
  center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
  radius = min(center[0], center[1]) - 10
  y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
  mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2

  # Apply mask to gradients
  gradients = gradients * mask

  # Normalize only the brain area
  brain_gradients = gradients[mask]
  if brain_gradients.max() > brain_gradients.min():
    gradients = (gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
  gradients[mask] = brain_gradients

  # Apply a higher threshold
  threshold = np.percentile(gradients[mask], 80)
  gradients[gradients < threshold] = 0

  # Apply more aggressive smoothing
  gradients = cv2.GaussianBlur(gradients, (11, 11), 0)

  # Create a heatmap overlay with enhanced contrast
  heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)
  heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)

  # Resize heatmap to match original image size
  heatmap = cv2.resize(heatmap, img_size)

  # Superimpose the heatmap on original image with increased opacity
  original_img = image.img_to_array(img)
  superimposed_img = heatmap * 0.7 + original_img * 0.3
  superimposed_img = superimposed_img.astype(np.uint8)

  img_path = os.path.join(output_dir, uploaded_file.name)
  with open(img_path, 'wb') as f:
    f.write(uploaded_file.getbuffer())

  saliency_map_path = f'saliency_maps/{uploaded_file.name}'

  # Save the saliency map
  cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))

  return superimposed_img


def load_xception_model(model_path):
  img_shape=(299, 299, 3)
  base_model = tf.keras.application.Xception(include_top=False, weights='imagenet', input_shape=img_shape, pooling='max')

  model = Sequential([
      base_model,
      Flatten(),
      Dropout(rate=0.3),
      Dense(128, activation='relu'),
      Dropout(rate=0.25),
      Dense(4, activation='softmax')
  ])

  model.build((None, ) + img_shape)

  # Compile the model
  model.compile(Adamax(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy', Precision(), Recall()
  ])

  model.load_weights(model_path)

  return model

 



st.title('Brain Tumor Classification')
st.write('Upload an image of a brain MRI scan to classify.')
uploaded_file = st.file_uploader('Choose an image...', type=['jpg', 'jpeg', 'png'])

if uploaded_file is not None:

  selected_model = st.radio(
      'Select Model',
      ('Transfer Learning - Xception', 'Custom CNN')
  )

  if selected_model == 'Transfer Learning - Xception':
    model, _ = load_model_and_history_from_file('xception_1_')
    img_size = (299, 299)
  else:
    model, _ = load_model_and_history_from_file('cnn1_')
    img_size = (224, 224)

  labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']
  img = image.load_img(uploaded_file, target_size=img_size)
  img_array = image.img_to_array(img)
  img_array = np.expand_dims(img_array, axis=0)
  img_array /= 255.0

  prediction = model.predict(img_array)

  # Get the class with the highest probability
  predicted_class_idx = np.argmax(prediction[0])
  predicted_class = labels[predicted_class_idx]

  st.write(f'Predicted Tumor Type: {predicted_class}')
  st.write('Prediction Probabilities:')

  for label, prob in zip(labels, prediction[0]):
    st.write(f'{label}: {prob * 100:.4f}%')

  saliency_map = generate_saliency_map(model, img_array, predicted_class_idx, img_size)

  col1, col2 = st.columns(2)

  with col1:
    st.image(uploaded_file, caption='Uploaded Image', use_container_width=True)
  with col2:
    st.image(saliency_map, caption='Saliency Map', use_container_width=True)

  st.write('## Clasification Results')

  result_container = st.container()
  result_container = st.container()
  result_container.markdown(
      f"""
      <div style='background-color: #000; color: #fff; padding: 30px; border-radius: 15px;;'>
        <div style='display: flex; justify-content: space-between; align-items: center;'>
          <div style='flex: 1, text-align: center;'>
            <h3 style='color: #fff; margin-bottom: 10px; font-size: 20px;'>Prediction</h3>
            <p style='font-size: 36px; font-weight: 800; color: #ff0000; margin: 0;'>
              {result}
            </p>
          </div>

          <div style='width: 2px; height: 80px; background-color: #fff; margin: 0 20px;'></div>
          <div style='flex: 1; text-align: center;'>
            <h3 style='color: #fff; margin-bottom: 10px; font-size: 20px;'>Confidence</h3>
            <p style='font-size: 36px; font-weight: 800; color: #2196F3; margin: 0;'>
              {prediction[0][class_index]:.4%}
            </p>
          </div>
          </div>
        </div>
      """,
      unsafe_allow_html=True
  )

  saliency_map_path = f'saliency_maps/{uploaded_file.name}'
  explanation = generate_explanation(saliency_map_path, predicted_class, prediction[0][predicted_class_idx])

  st.write('Explanation:')
  st.write(explanation)
